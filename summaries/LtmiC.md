# 심층강화학습을 이용한 군중 시뮬레이션
이재동, 이제희, KCGS 2018

## Summary
- 본 논문은 사람의 움직임인 인지-사고-행동의 과정을 심층강화하급을 통해 구조화함
- 배우-비평가 모델 중 하나인 심층 결정론적 정책 기울기를 이용함

## Method
- 객체의 이산화된 깊이정보를 시각정보로 활용했음
- 이산화된 깊이 정보 : 객체가 바라보는 방향을 기준으로 190°의 시야에 대해 매 10°마다 측정한 깊이 정보
- 충돌을 피하며 목적지에 도달할 수 있도록 보상 체계 설정
- 시작정보를 이용한 학습도니 정책 사용
- 배우-비평가(Actor-Critic), 심층 결정론적 정책 기울기(DDPG) 사용

### 객체
- 객체의 상태 = 신체상태 + 센서상태
- 신체 상태 = 위치 + 속도 + 목적지까지의 방향 + 최근 3프레임의 이상화된 깊이정보
- 매프레임마다 객체의 (속력,방향) += (속력의 변화량,방향의 변화량)
- 객체의 위치 += 속력*방향

### 사용된 네트워크 구조
- 배우-비평가 네트워크 : 배우 네트워크 + 비평가 네트워크
- 배우 네트워크 = 신체 상태 입력 네트워크 + 센서 상태 입력 네트워크
- 비평가 네트워크 = 배우 네트워크 + 행동 값 입력 네트워크
- 배우 네트워크는 **객체의 행동 결정**, 비평가 네트워크는 입력된 **행동에 대한 평가 가치**를 출력(기준 : 사용자 설계 보상 체제에 의해 결정)
- 최종적으로 보상의 합이 최대가 되도록 학습됨
- 목적지까지 도달하기 위한 보상 = 1/((목적지까지의 거리)*(목적지까지의 거리)) 즉, **가까워질수록 높은 보상**
- 충돌시 고정된 음수값으로 보상

## Implement
- 4~5시간 학습함
- 4가지 시나리오(장애물 회피, 원형 교차, 복도 교차, 수직 교차)에 대해 실험함